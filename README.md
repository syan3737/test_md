> 本期嘉宾：林政豪<br/>
> 话题：深度学习

在过去的几年中，深度神经网络给很多机器学习任务带来了质的提高。从物体识别到机器翻译，很多任务已经实现了超过人类平均水平的精度。然而精度的提升背后的代价是数以百万计的参数和几天甚至几周在不止一个显卡上的运算需求。大量的功耗限制了深度学习模型在手表手机等小型电子设备上的应用。那么我们该如何在不损失太多精度的同时，给深度神经网络做减法呢？



# 提到的一些内容

* [林政豪个人主页](http://cseweb.ucsd.edu/~jel252/)
* 节目中多次提到的通过改变连接方式减少参数，增加深度的残差网络ResNet：
[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)
* 在讲到agnostic的设定下，我们提到了 [PAC Learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)
* 节目开始时提到的可以用来标识数据的众包平台 [Amazon Mechanical Turk](https://www.mturk.com/mturk/welcome)

# 怎么收听

* 蜻蜓FM：点击左下角**阅读原文**
* 网易云音乐：[点击这里](http://www.qingting.fm/channels/225623/programs/7773331)
* 官方网站：[点击这里](http://music.163.com/#/program?id=909366178)
